# ğŸ§  Smart RAG System

A powerful Retrieval-Augmented Generation (RAG) system for multimodal document understanding, comparison, summarization, and conversational querying with memory.

## ğŸš€ Features

- ğŸ“„ Upload PDFs, DOCX, images, audio, URLs, and YouTube transcripts
- ğŸ” Ask questions about uploaded content using Groq's LLMs (e.g., LLaMA3-70B)
- ğŸ§  Memory-enabled chat using ChromaDB (retrieves last 30 exchanges per session)
- ğŸ“š Document Comparison and Summarization
- ğŸ“¦ FastAPI backend with modular architecture
- ğŸ¯ Chunk â†’ Retrieve â†’ Augment â†’ Generate (CRAG pipeline)
- ğŸ§  Reranking using `bge-reranker-large`
- âœ¨ Built-in support for OCR, transcription, and file parsing

## ğŸ› ï¸ Tech Stack

- **FastAPI** â€“ Backend API
- **Groq API** â€“ LLM inference (LLaMA3, Mixtral)
- **SentenceTransformers** â€“ Embeddings (`e5-large-v2`)
- **FAISS** â€“ Vector store for chunk retrieval
- **ChromaDB** â€“ Chat memory store
- **FasterWhisper** â€“ Audio transcription
- **Pytesseract / pdfplumber / PyMuPDF** â€“ Parsing and OCR
- **Cohere Reranker** â€“ Semantic reranking of chunks

## ğŸ“‚ Folder Structure

app/
â”œâ”€â”€ Routes/ # API endpoints
â”‚ â”œâ”€â”€ upload.py
â”‚ â”œâ”€â”€ query.py
â”‚ â”œâ”€â”€ compare.py
â”‚ â””â”€â”€ convert.py
â”œâ”€â”€ Services/ # Core logic (retriever, llm, embedder, etc.)
â”‚ â”œâ”€â”€ extractor.py
â”‚ â”œâ”€â”€ retriever.py
â”‚ â”œâ”€â”€ embedder.py
â”‚ â””â”€â”€ vector_db.py
â”œâ”€â”€ Memory/
â”‚ â””â”€â”€ memory_db.py # Chat memory using ChromaDB
â”œâ”€â”€ parser/ # File parsing logic (PDF, DOCX, image, audio, URL)
â””â”€â”€ main.py # FastAPI app entry point

Create a Conda environment
    conda create -n rag-env python=3.10
    conda activate rag-env

Install dependencies
    pip install -r requirements.txt

Set up your .env file
    GROQ_API_KEY=your_api_key
    GROQ_MODEL=llama3-70b-8192

Run the FastAPI app
    uvicorn app.main:app --reload


